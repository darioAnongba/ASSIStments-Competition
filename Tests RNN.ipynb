{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler, Sampler\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.init import xavier_normal, kaiming_normal\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "DATA_DIR = 'Data/'\n",
    "SEED = 7\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "categorical_features = set(['SY ASSISTments Usage',\n",
    "                        'skill',\n",
    "                        'problemId',\n",
    "                        'assignmentId',\n",
    "                        'assistmentId',\n",
    "                        'problemType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>problemId</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>assistmentId</th>\n",
       "      <th>timeTaken</th>\n",
       "      <th>correct</th>\n",
       "      <th>original</th>\n",
       "      <th>hint</th>\n",
       "      <th>hintCount</th>\n",
       "      <th>hintTotal</th>\n",
       "      <th>...</th>\n",
       "      <th>confidence(CONFUSED)</th>\n",
       "      <th>confidence(FRUSTRATED)</th>\n",
       "      <th>confidence(OFF TASK)</th>\n",
       "      <th>confidence(GAMING)</th>\n",
       "      <th>RES_BORED</th>\n",
       "      <th>RES_CONCENTRATING</th>\n",
       "      <th>RES_CONFUSED</th>\n",
       "      <th>RES_FRUSTRATED</th>\n",
       "      <th>RES_OFFTASK</th>\n",
       "      <th>RES_GAMING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184889</th>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.964286</td>\n",
       "      <td>-0.964286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.376427</td>\n",
       "      <td>0.320317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785585</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.980798</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>0.225154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184891</th>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.989799</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>0.665929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.149121</td>\n",
       "      <td>0.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184892</th>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.994599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>0.780156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.468252</td>\n",
       "      <td>0.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184893</th>\n",
       "      <td>43</td>\n",
       "      <td>971</td>\n",
       "      <td>13</td>\n",
       "      <td>268</td>\n",
       "      <td>-0.979598</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.186970</td>\n",
       "      <td>0.376427</td>\n",
       "      <td>0.195349</td>\n",
       "      <td>0.060808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440265</td>\n",
       "      <td>0.005797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        skill  problemId  assignmentId  assistmentId  timeTaken  correct  \\\n",
       "184889     78         83            13            18  -0.997000        0   \n",
       "184890     78         80            13            18  -0.980798        1   \n",
       "184891     78         81            13            18  -0.989799        1   \n",
       "184892     78         82            13            18  -0.994599        1   \n",
       "184893     43        971            13           268  -0.979598        0   \n",
       "\n",
       "        original  hint  hintCount  hintTotal     ...      \\\n",
       "184889         1     1  -0.964286  -0.964286     ...       \n",
       "184890         0     0  -1.000000  -1.000000     ...       \n",
       "184891         0     0  -1.000000  -1.000000     ...       \n",
       "184892         0     0  -1.000000  -1.000000     ...       \n",
       "184893         1     0  -1.000000  -1.000000     ...       \n",
       "\n",
       "        confidence(CONFUSED)  confidence(FRUSTRATED)  confidence(OFF TASK)  \\\n",
       "184889              0.000000                0.000000              0.838710   \n",
       "184890              0.000000                0.091463              0.000000   \n",
       "184891              0.000000                0.091463              0.280702   \n",
       "184892              0.000000                0.091463              0.600000   \n",
       "184893              0.378151                0.000000              0.578947   \n",
       "\n",
       "        confidence(GAMING)  RES_BORED  RES_CONCENTRATING  RES_CONFUSED  \\\n",
       "184889            0.008522   0.376427           0.320317      0.000000   \n",
       "184890            0.047821   0.156027           0.225154      0.000000   \n",
       "184891            0.047821   0.156027           0.665929      0.000000   \n",
       "184892            0.047821   0.156027           0.780156      0.000000   \n",
       "184893            0.186970   0.376427           0.195349      0.060808   \n",
       "\n",
       "        RES_FRUSTRATED  RES_OFFTASK  RES_GAMING  \n",
       "184889        0.000000     0.785585    0.000264  \n",
       "184890        0.009561     0.000000    0.001483  \n",
       "184891        0.009561     0.149121    0.001483  \n",
       "184892        0.009561     0.468252    0.001483  \n",
       "184893        0.000000     0.440265    0.005797  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_train = open(DATA_DIR + \"student_train_logs.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_train)\n",
    "\n",
    "train[9][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = train[9][0].shape[1] + train[9][1].shape[1]\n",
    "validation_set_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {k:v for k, v in random.sample(train.items(), validation_set_size)}\n",
    "train_truncated = { k : train[k] for k in set(train) - set(validation) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.idx = list(sequences.keys())\n",
    "        self.sequences = sequences\n",
    "        #self.weights = [0.3 if x[2] == 0 else 0.8 for x in self.sequences.values()]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 5\n",
    "        #return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        student_id = self.idx[id]\n",
    "        \n",
    "        actions = self.sequences[student_id][0].as_matrix().astype(np.float32)\n",
    "        fixed = self.sequences[student_id][1].as_matrix().astype(np.float32)\n",
    "        target = np.asarray([self.sequences[student_id][2]]).astype(np.float32)\n",
    "        seq = np.hstack([fixed, actions])\n",
    "\n",
    "        return student_id, seq, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_truncated)\n",
    "validation_dataset = DataSet(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, bi, use_gpu=True):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bi = bi\n",
    "        self.output_dim = output_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          dropout=0.25,\n",
    "                          bidirectional=bi)\n",
    "        if bi:\n",
    "            self.decoder = nn.Linear(hidden_dim*2, output_dim)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def weights_init(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.dim() >= 2:\n",
    "                kaiming_normal(param)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.bi:\n",
    "            if self.use_gpu:\n",
    "                return Variable(torch.zeros(self.n_layers*2, batch_size, self.hidden_dim)).cuda()\n",
    "            else:\n",
    "                return Variable(torch.zeros(self.n_layers*2, batch_size, self.hidden_dim))\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim)).cuda()\n",
    "        else:\n",
    "            return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim))\n",
    "\n",
    "    \n",
    "    def forward(self, actions):\n",
    "        batch_size = actions.size(1)\n",
    "        hidden_state = self.init_hidden(batch_size)\n",
    "        out, _ = self.gru(actions, hidden_state)\n",
    "        out = out[-1,:,:]                                                                                                         \n",
    "        out = self.decoder(out)                                                                                                   \n",
    "        out = out.view(batch_size, self.output_dim)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def step(self, inp, target):                                                                                                        \n",
    "        self.zero_grad()                                                                                                           \n",
    "        output = self.forward(inp)                                                                                                      \n",
    "        loss = self.criterion(output, target.float())                                                                      \n",
    "        loss.backward()                                                                                                                 \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.data[0], F.sigmoid(output)\n",
    "    \n",
    "    \n",
    "    def evaluate_val(self, dataset):\n",
    "        loader = DataLoader(dataset, batch_size=1, num_workers=4)\n",
    "        \n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        \n",
    "        for i, (_, actions, target) in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "            y_true.append(target.numpy()[0,0])\n",
    "            \n",
    "            actions = actions.permute(1, 0, 2)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                actions = Variable(actions).cuda()\n",
    "            else:\n",
    "                actions = Variable(actions)\n",
    "                \n",
    "            output = self.forward(actions)\n",
    "            output = F.sigmoid(output)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                y_preds.append(output.squeeze().cpu().data[0])\n",
    "            else:\n",
    "                y_preds.append(output.squeeze().data[0])\n",
    "                \n",
    "        return y_true, y_preds\n",
    "    \n",
    "    \n",
    "    def predict(self, test_set):\n",
    "        loader = DataLoader(test_set, batch_size=1, num_workers=4)\n",
    "        \n",
    "        preds = []\n",
    "        \n",
    "        for i, actions in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "            actions = actions.permute(1, 0, 2)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                actions = Variable(actions).cuda()\n",
    "            else:\n",
    "                actions = Variable(actions)\n",
    "            \n",
    "            output = self.forward(actions)\n",
    "            output = F.sigmoid(output)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                preds.append(output.squeeze().cpu().data[0])\n",
    "            else:\n",
    "                preds.append(output.squeeze().data[0])\n",
    "                \n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def fit(self, train_dataset):\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adamax(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        #sampler = WeightedRandomSampler(train_dataset.weights, num_samples=len(train_dataset))\n",
    "        loader = DataLoader(train_dataset, batch_size=1, num_workers=4, shuffle=True)\n",
    "        \n",
    "        e_losses = []\n",
    "        e_accs = []\n",
    "        e_aucs = []\n",
    "        \n",
    "        e_val_accs = []\n",
    "        e_val_aucs = []\n",
    "\n",
    "        e_bar = tqdm_notebook(range(10))\n",
    "        \n",
    "        for e in e_bar:\n",
    "            self.train()\n",
    "            e_loss = 0\n",
    "            preds = []\n",
    "            targets = []\n",
    "            val_preds = []\n",
    "            \n",
    "            for i, (_, seq, label) in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "                seq = seq.permute(1,0,2)\n",
    "                \n",
    "                if self.use_gpu:\n",
    "                    seq_var = Variable(seq).cuda()\n",
    "                    label_var = Variable(label).cuda()\n",
    "                else:\n",
    "                    seq_var = Variable(seq)\n",
    "                    label_var =  Variable(label)\n",
    "                \n",
    "                loss, output = self.step(seq_var, label_var)\n",
    "                e_loss += loss\n",
    "                \n",
    "                preds.append(output.squeeze().cpu().data[0])\n",
    "                targets.append(label.numpy()[0,0])\n",
    "            \n",
    "            preds = np.array(preds)\n",
    "            targets = np.array(targets)\n",
    "            auc = roc_auc_score(targets, preds)\n",
    "            \n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            acc = accuracy_score(preds, targets)\n",
    "            \n",
    "            e_losses.append(e_loss / (i+1))\n",
    "            e_accs.append(acc)\n",
    "            e_aucs.append(auc)\n",
    "\n",
    "            # Validation set accuracy and AUC\n",
    "            val_acc = None\n",
    "            val_auc = None\n",
    "            if validation_dataset is not None:\n",
    "                val_targets, val_preds = self.evaluate_val(validation_dataset)\n",
    "                val_targets = np.array(val_targets)\n",
    "                val_preds = np.array(val_preds)\n",
    "                val_auc = roc_auc_score(val_targets, val_preds)\n",
    "\n",
    "                val_preds[val_preds >= 0.5] = 1\n",
    "                val_preds[val_preds < 0.5] = 0\n",
    "                val_acc = accuracy_score(val_preds, val_targets)\n",
    "\n",
    "                e_val_accs.append(val_acc)\n",
    "                e_val_aucs.append(val_auc)\n",
    "            \n",
    "            e_bar.set_postfix(acc=acc, e_loss=e_losses[-1], auc=auc, val_acc=val_acc, val_auc=val_auc)\n",
    "      \n",
    "        return e_losses, e_accs, e_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_dim=input_dim, hidden_dim=256, output_dim=1, n_layers=3, bi=True, use_gpu=True)\n",
    "#model.weights_init()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a25a13f5794ba4877cefb958666a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bb95d567c64826a699e25fec168f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50f4b2b0fa6453584e1d18ef2ea4562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9c4cf11c5740ea82cbd47e1249111e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-91:\n",
      "Process Process-90:\n",
      "Process Process-89:\n",
      "Process Process-92:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c44333722c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_aucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-e7411b23291e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataset)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0mlabel_var\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0me_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-e7411b23291e>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, inp, target)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e_losses, e_accs, e_aucs = model.fit(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
