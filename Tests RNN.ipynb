{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler, Sampler\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.init import xavier_normal, kaiming_normal\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "DATA_DIR = 'Data/'\n",
    "SEED = 7\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "categorical_features = set(['SY ASSISTments Usage',\n",
    "                        'skill',\n",
    "                        'problemId',\n",
    "                        'assignmentId',\n",
    "                        'assistmentId',\n",
    "                        'problemType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_train = open(DATA_DIR + \"student_train_logs.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_train)\n",
    "\n",
    "train[9][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train[9][0].shape[1] + train[9][1].shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSet(Dataset):\n",
    "    def __init__(self):\n",
    "        self.idx = list(train.keys())\n",
    "        self.sequences = train\n",
    "        self.weights = [0.3 if x[2] == 0 else 0.8 for x in self.sequences.values()]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        student_id = self.idx[id]\n",
    "        \n",
    "        actions = self.sequences[student_id][0].as_matrix().astype(np.float32)\n",
    "        fixed = self.sequences[student_id][1].as_matrix().astype(np.float32)\n",
    "        target = np.asarray([self.sequences[student_id][2]]).astype(np.float32)\n",
    "        seq = np.hstack([fixed, actions])\n",
    "\n",
    "        return student_id, seq, target\n",
    "\n",
    "    \n",
    "train_dataset = TrainingSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, bi, use_gpu=True):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bi = bi\n",
    "        self.output_dim = output_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          dropout=0.25,\n",
    "                          bidirectional=bi)\n",
    "        if bi:\n",
    "            self.decoder = nn.Linear(hidden_dim*2, output_dim)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.dim() >= 2:\n",
    "                kaiming_normal(param)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.bi:\n",
    "            if self.use_gpu:\n",
    "                return Variable(torch.zeros(self.n_layers*2, batch_size, self.hidden_dim)).cuda()\n",
    "            else:\n",
    "                return Variable(torch.zeros(self.n_layers*2, batch_size, self.hidden_dim))\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim)).cuda()\n",
    "        else:\n",
    "            return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim))\n",
    "        \n",
    "    \n",
    "    def forward(self, actions):\n",
    "        batch_size = actions.size(1)\n",
    "        hidden_state = self.init_hidden(batch_size)\n",
    "        out, _ = self.gru(actions, hidden_state)\n",
    "        out = out[-1,:,:]                                                                                                         \n",
    "        out = self.decoder(out)                                                                                                   \n",
    "        out = out.view(batch_size, self.output_dim)                                                                              \n",
    "        return out\n",
    "    \n",
    "    def step(self, inp, target):                                                                                                        \n",
    "        self.zero_grad()                                                                                                           \n",
    "        output = self.forward(inp)                                                                                                      \n",
    "        loss = self.criterion(output, target.float())                                                                      \n",
    "        loss.backward()                                                                                                                 \n",
    "        self.optimizer.step()                                                                                                           \n",
    "        return loss.data[0], F.sigmoid(output)\n",
    "    \n",
    "    def fit(self, train_dataset):\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adamax(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        sampler = WeightedRandomSampler(train_dataset.weights, num_samples=len(train_dataset))\n",
    "        loader = DataLoader(train_dataset, batch_size=1, num_workers=4, sampler=sampler)\n",
    "        e_losses = []\n",
    "        e_accs = []\n",
    "        e_aucs = []\n",
    "        e_bar = tqdm_notebook(range(10))\n",
    "        for e in e_bar:\n",
    "            self.train()\n",
    "            e_loss = 0\n",
    "            preds = []\n",
    "            targets = []\n",
    "            for i, (_, seq, label) in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "                seq = seq.permute(1,0,2)\n",
    "                \n",
    "                if self.use_gpu:\n",
    "                    seq_var = Variable(seq).cuda()\n",
    "                    label_var = Variable(label).cuda()\n",
    "                else:\n",
    "                    seq_var = Variable(seq)\n",
    "                    label_var =  Variable(label)\n",
    "                \n",
    "                loss, output = self.step(seq_var, label_var)\n",
    "                \n",
    "                e_loss += loss\n",
    "                preds.append(output.squeeze().cpu().data[0])\n",
    "                targets.append(label.numpy()[0,0])\n",
    "            preds = np.array(preds)\n",
    "            targets = np.array(targets)\n",
    "            auc = roc_auc_score(targets, preds)\n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            \n",
    "            acc = accuracy_score(preds, targets)\n",
    "            e_losses.append(e_loss / (i+1))\n",
    "            e_accs.append(acc)\n",
    "            e_aucs.append(auc)\n",
    "            e_bar.set_postfix(acc=acc, e_loss=e_losses[-1], auc=auc)\n",
    "            \n",
    "            \n",
    "        return e_losses, e_accs, e_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_dim=input_dim, hidden_dim=256, output_dim=1, n_layers=3, bi=False, use_gpu=True)\n",
    "model.weights_init()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses, e_accs, e_aucs = model.fit(train_dataset)\n",
    "\n",
    "plt.plot(e_losses)\n",
    "plt.plot(e_accs)\n",
    "plt.plot(e_aucs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
