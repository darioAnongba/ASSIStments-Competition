{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSet(Dataset):\n",
    "    def __init__(self):\n",
    "        self.idx = list(train.keys())\n",
    "        self.sequences = train\n",
    "        self.weights = [0.3 if x[2] == 0 else 0.8 for x in self.sequences.values()]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        student_id = self.idx[id]\n",
    "        \n",
    "        actions = self.sequences[student_id][0].as_matrix().astype(np.float32)\n",
    "        fixed = self.sequences[student_id][1].as_matrix().astype(np.float32)\n",
    "        target = np.asarray([self.sequences[student_id][2]]).astype(np.float32)\n",
    "        fixed_rep = np.repeat(fixed[np.newaxis, ...], actions.shape[0], axis=0)\n",
    "        seq = np.hstack([fixed_rep, actions])\n",
    "        return student_id, seq[:,keep_indices], target\n",
    "\n",
    "\n",
    "train_dataset = TrainingSet()\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim,\n",
    "                n_layers, bi):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bi = bi\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_dim, hidden_size=hidden_dim,\n",
    "                         num_layers=n_layers, dropout=0,\n",
    "                          bidirectional=bi)\n",
    "        if bi:\n",
    "            self.decoder = nn.Linear(hidden_dim*2, output_dim)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.dim() >= 2:\n",
    "                kaiming_normal(param)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.bi:\n",
    "            return Variable(torch.zeros(self.n_layers*2, batch_size, self.hidden_dim)).cuda()\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim)).cuda()\n",
    "    \n",
    "    def forward(self, actions):\n",
    "        batch_size = actions.size(1)\n",
    "        hidden_state = self.init_hidden(batch_size)\n",
    "        out, _ = self.gru(actions, hidden_state)\n",
    "        out = out[-1,:,:]                                                                                                         \n",
    "        out = self.decoder(out)                                                                                                   \n",
    "        out = out.view(batch_size, self.output_dim)                                                                              \n",
    "        return out\n",
    "    \n",
    "    def step(self, inp, target):                                                                                                        \n",
    "        self.zero_grad()                                                                                                           \n",
    "        output = self.forward(inp)                                                                                                      \n",
    "        loss = self.criterion(output, target.float())                                                                      \n",
    "        loss.backward()                                                                                                                 \n",
    "        self.optimizer.step()                                                                                                           \n",
    "        return loss.data[0], F.sigmoid(output)\n",
    "    \n",
    "    def fit(self, train_dataset):\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adamax(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        sampler = WeightedRandomSampler(train_dataset.weights, num_samples=len(train_dataset))\n",
    "        loader = DataLoader(train_dataset, batch_size=1, num_workers=4, sampler=sampler)\n",
    "        e_losses = []\n",
    "        e_accs = []\n",
    "        e_aucs = []\n",
    "        e_bar = tqdm(range(10))\n",
    "        for e in e_bar:\n",
    "            self.train()\n",
    "            e_loss = 0\n",
    "            preds = []\n",
    "            targets = []\n",
    "            for i, (_, seq, label) in enumerate(tqdm(loader, leave=False)):\n",
    "                seq = seq.permute(1,0,2)\n",
    "                loss, output = self.step(Variable(seq).cuda(),\n",
    "                          Variable(label).cuda())\n",
    "                e_loss += loss\n",
    "                preds.append(output.squeeze().cpu().data[0])\n",
    "                targets.append(label.numpy()[0,0])\n",
    "            preds = np.array(preds)\n",
    "            targets = np.array(targets)\n",
    "            auc = roc_auc_score(targets, preds)\n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            \n",
    "            acc = accuracy_score(preds, targets)\n",
    "            e_losses.append(e_loss / (i+1))\n",
    "            e_accs.append(acc)\n",
    "            e_aucs.append(auc)\n",
    "            e_bar.set_postfix(acc=acc, e_loss=e_losses[-1], auc=auc)\n",
    "            \n",
    "            \n",
    "        return e_losses, e_accs, e_aucs\n",
    "\n",
    "\n",
    "# In[92]:\n",
    "\n",
    "\n",
    "model = RNN(input_dim=len(keep_indices), hidden_dim=256, output_dim=1, n_layers=3, bi=False)\n",
    "model.weights_init()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "# In[93]:\n",
    "\n",
    "\n",
    "e_losses, e_accs, e_aucs = model.fit(train_dataset)\n",
    "\n",
    "plt.plot(e_losses)\n",
    "plt.plot(e_accs)\n",
    "plt.plot(e_aucs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
