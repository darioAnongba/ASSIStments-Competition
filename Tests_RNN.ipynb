{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler, Sampler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "DATA_DIR = 'Data/'\n",
    "SEED = 7\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "categorical_features = set(['skill',\n",
    "                        'problemId',\n",
    "                        'assignmentId',\n",
    "                        'assistmentId',\n",
    "                        'problemType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_train = open(DATA_DIR + \"student_train_logs.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_train)\n",
    "\n",
    "train[9][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_size = 30\n",
    "input_dim = train[9][0].shape[1]\n",
    "fixed_dim = train[9][1].shape[0]\n",
    "hidden_dim = 256\n",
    "dropout = 0.25\n",
    "n_layers = 3\n",
    "bidirectional = True\n",
    "use_gpu = True\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = {k:v for k, v in random.sample(train.items(), validation_set_size)}\n",
    "train_truncated = { k : train[k] for k in set(train) - set(validation) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.idx = list(sequences.keys())\n",
    "        self.sequences = sequences\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        student_id = self.idx[id]\n",
    "        \n",
    "        dynamic = self.sequences[student_id][0].as_matrix().astype(np.float32)\n",
    "        fixed = self.sequences[student_id][1].as_matrix().astype(np.float32)\n",
    "        target = np.asarray([self.sequences[student_id][2]]).astype(np.float32)\n",
    "\n",
    "        return student_id, dynamic, fixed, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_truncated)\n",
    "validation_dataset = DataSet(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, fixed_dim, n_layers, bi, use_gpu, output_dim=1, batch_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bi = bi\n",
    "        self.output_dim = output_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          dropout=dropout,\n",
    "                          bidirectional=bi)\n",
    "        if bi:\n",
    "            self.decoder = nn.Linear(hidden_dim*2 + fixed_dim, output_dim)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(hidden_dim + fixed_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.bi:\n",
    "            if self.use_gpu:\n",
    "                return Variable(torch.zeros(self.n_layers*2, self.batch_size, self.hidden_dim)).cuda()\n",
    "            else:\n",
    "                return Variable(torch.zeros(self.n_layers*2, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(self.n_layers, self.batch_size, self.hidden_dim)).cuda()\n",
    "        else:\n",
    "            return Variable(torch.zeros(self.n_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    \n",
    "    def forward(self, actions, fixed):\n",
    "        hidden_state = self.init_hidden()\n",
    "        out, _ = self.gru(actions, hidden_state)\n",
    "        out = self.decoder(torch.cat([out[-1, :, :], fixed], dim=1))                                                                                                   \n",
    "        out = out.view(self.batch_size, self.output_dim)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def step(self, dynamic, fixed, target):                                                                                                        \n",
    "        self.zero_grad()                                                                                                           \n",
    "        output = self.forward(dynamic, fixed)                                                                                                      \n",
    "        loss = self.criterion(output, target.float())                                                                      \n",
    "        loss.backward()                                                                                                                 \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.data[0], F.sigmoid(output)\n",
    "    \n",
    "    \n",
    "    def evaluate_val(self, dataset):\n",
    "        loader = DataLoader(dataset, self.batch_size, num_workers=num_workers)\n",
    "        \n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        \n",
    "        for i, (_, actions, fixed, target) in enumerate(tqdm(loader, leave=False)):\n",
    "            y_true.append(target.float())\n",
    "            \n",
    "            actions = actions.permute(1, 0, 2)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                actions = Variable(actions).cuda()\n",
    "                fixed = Variable(fixed).cuda()\n",
    "            else:\n",
    "                actions = Variable(actions)\n",
    "                fixed = Variable(fixed)\n",
    "                \n",
    "            output = self.forward(actions, fixed)\n",
    "            output = F.sigmoid(output)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                y_preds.append(output.squeeze().cpu().data[0])\n",
    "            else:\n",
    "                y_preds.append(output.squeeze().data[0])\n",
    "                \n",
    "        return y_true, y_preds\n",
    "    \n",
    "    \n",
    "    def fit(self, train_dataset):\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adamax(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "        \n",
    "        e_losses = []\n",
    "        e_accs = []\n",
    "        e_aucs = []\n",
    "        \n",
    "        e_val_accs = []\n",
    "        e_val_aucs = []\n",
    "        \n",
    "        e_bar = tqdm_notebook(range(epochs))\n",
    "        for e in e_bar:\n",
    "            self.train()\n",
    "            e_loss = 0\n",
    "            preds = []\n",
    "            targets = []\n",
    "            val_preds = []\n",
    "            \n",
    "            for i, (_, seq, fixed, label) in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "                seq = seq.permute(1,0,2)\n",
    "                \n",
    "                if self.use_gpu:\n",
    "                    seq_var = Variable(seq).cuda()\n",
    "                    fixed_var = Variable(fixed).cuda()\n",
    "                    label_var = Variable(label).cuda()\n",
    "                else:\n",
    "                    seq_var = Variable(seq)\n",
    "                    fixed_var = Variable(fixed)\n",
    "                    label_var =  Variable(label)\n",
    "                \n",
    "                loss, output = self.step(seq_var, fixed_var, label_var)\n",
    "                e_loss += loss\n",
    "                \n",
    "                preds.append(output.squeeze().cpu().data[0])\n",
    "                targets.append(label.float())\n",
    "            \n",
    "            preds = np.array(preds)\n",
    "            targets = np.array(targets)\n",
    "            auc = roc_auc_score(targets, preds)\n",
    "            \n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            acc = accuracy_score(preds, targets)\n",
    "            \n",
    "            e_losses.append(e_loss / (i+1))\n",
    "            e_accs.append(acc)\n",
    "            e_aucs.append(auc)\n",
    "\n",
    "            # Validation set accuracy and AUC\n",
    "            val_acc = None\n",
    "            val_auc = None\n",
    "            if validation_dataset is not None:\n",
    "                val_targets, val_preds = self.evaluate_val(validation_dataset)\n",
    "                val_targets = np.array(val_targets)\n",
    "                val_preds = np.array(val_preds)\n",
    "                val_auc = roc_auc_score(val_targets, val_preds)\n",
    "\n",
    "                val_preds[val_preds >= 0.5] = 1\n",
    "                val_preds[val_preds < 0.5] = 0\n",
    "                val_acc = accuracy_score(val_preds, val_targets)\n",
    "\n",
    "                e_val_accs.append(val_acc)\n",
    "                e_val_aucs.append(val_auc)\n",
    "            \n",
    "            e_bar.set_postfix(acc=acc, e_loss=e_losses[-1], auc=auc, val_acc=val_acc, val_auc=val_auc)\n",
    "      \n",
    "        return e_losses, e_accs, e_aucs, e_val_accs, e_val_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4186a6f325c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = RNN(input_dim=input_dim,\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mfixed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mbi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "model = RNN(input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            fixed_dim=fixed_dim,\n",
    "            n_layers=n_layers,\n",
    "            bi=bidirectional,\n",
    "            use_gpu=use_gpu)\n",
    "model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses, e_accs, e_aucs, e_val_accs, e_val_aucs = model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracies')\n",
    "print(e_accs, e_val_accs)\n",
    "\n",
    "print('ROC AUC')\n",
    "print(e_aucs, e_val_aucs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
