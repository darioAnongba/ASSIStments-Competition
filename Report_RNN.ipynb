{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSISTments Data Mining Competition 2017 - Report of RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler, Sampler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "DATA_DIR = 'Data/'\n",
    "RESULTS_DIR = 'Results/'\n",
    "SEED = 7\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "categorical_features = set(['skill',\n",
    "                        'problemId',\n",
    "                        'assignmentId',\n",
    "                        'assistmentId',\n",
    "                        'problemType'])\n",
    "\n",
    "def save_pickle(dict_data, name):\n",
    "    pickle_out = open(RESULTS_DIR + name + '.pickle', 'wb')\n",
    "    pickle.dump(dict_data, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training data\n",
    "\n",
    "The training data is stored in pickles as a dictionary where the keys are student ids and and values are tuples of **(Sequence of dynamic features, array of fixed features, target)**:\n",
    "\n",
    "- **Dynamic features**: Features that can potentially contain different values per action in a sequence. Stored as a pandas dataframe sorted by time.\n",
    "- **Fixed features**: Features that are unchanged through time. Ex: Average correctness, the school id or MCAS grade. Stored as a pandas Series.\n",
    "- **target**: Either yes (1) or no (0) the student has chosen a carrer in STEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeTaken</th>\n",
       "      <th>correct</th>\n",
       "      <th>original</th>\n",
       "      <th>hint</th>\n",
       "      <th>hintCount</th>\n",
       "      <th>hintTotal</th>\n",
       "      <th>scaffold</th>\n",
       "      <th>bottomHint</th>\n",
       "      <th>attemptCount</th>\n",
       "      <th>frIsHelpRequest</th>\n",
       "      <th>...</th>\n",
       "      <th>problemId_2</th>\n",
       "      <th>problemType_0</th>\n",
       "      <th>problemType_1</th>\n",
       "      <th>problemType_2</th>\n",
       "      <th>assignmentId_0</th>\n",
       "      <th>assignmentId_1</th>\n",
       "      <th>assignmentId_2</th>\n",
       "      <th>assistmentId_0</th>\n",
       "      <th>assistmentId_1</th>\n",
       "      <th>assistmentId_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184889</th>\n",
       "      <td>-0.204775</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.110312</td>\n",
       "      <td>-0.325670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571236</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964225</td>\n",
       "      <td>-0.667735</td>\n",
       "      <td>0.451322</td>\n",
       "      <td>1.241278</td>\n",
       "      <td>0.290601</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>-0.538666</td>\n",
       "      <td>-1.568210</td>\n",
       "      <td>-0.594635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>0.919916</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.615193</td>\n",
       "      <td>-0.667056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571236</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.419032</td>\n",
       "      <td>-0.667735</td>\n",
       "      <td>0.451322</td>\n",
       "      <td>1.241278</td>\n",
       "      <td>0.290601</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>-0.538666</td>\n",
       "      <td>-1.568210</td>\n",
       "      <td>-0.594635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184891</th>\n",
       "      <td>0.295088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.615193</td>\n",
       "      <td>-0.667056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571236</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106654</td>\n",
       "      <td>-0.667735</td>\n",
       "      <td>0.451322</td>\n",
       "      <td>1.241278</td>\n",
       "      <td>0.290601</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>-0.538666</td>\n",
       "      <td>-1.568210</td>\n",
       "      <td>-0.594635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184892</th>\n",
       "      <td>-0.038154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.615193</td>\n",
       "      <td>-0.667056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571236</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.168239</td>\n",
       "      <td>-0.667735</td>\n",
       "      <td>0.451322</td>\n",
       "      <td>1.241278</td>\n",
       "      <td>0.290601</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>-0.538666</td>\n",
       "      <td>-1.568210</td>\n",
       "      <td>-0.594635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184893</th>\n",
       "      <td>1.003227</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.615193</td>\n",
       "      <td>-0.667056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571236</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239056</td>\n",
       "      <td>1.894327</td>\n",
       "      <td>1.007370</td>\n",
       "      <td>-0.444943</td>\n",
       "      <td>0.290601</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>-0.141623</td>\n",
       "      <td>-0.646897</td>\n",
       "      <td>-0.073348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timeTaken  correct  original  hint  hintCount  hintTotal  scaffold  \\\n",
       "184889  -0.204775        0         1     1  -0.110312  -0.325670         0   \n",
       "184890   0.919916        1         0     0  -0.615193  -0.667056         1   \n",
       "184891   0.295088        1         0     0  -0.615193  -0.667056         1   \n",
       "184892  -0.038154        1         0     0  -0.615193  -0.667056         1   \n",
       "184893   1.003227        0         1     0  -0.615193  -0.667056         0   \n",
       "\n",
       "        bottomHint  attemptCount  frIsHelpRequest       ...        \\\n",
       "184889           0     -0.571236                1       ...         \n",
       "184890           0     -0.571236                1       ...         \n",
       "184891           0     -0.571236                1       ...         \n",
       "184892           0     -0.571236                1       ...         \n",
       "184893           0     -0.571236                0       ...         \n",
       "\n",
       "        problemId_2  problemType_0  problemType_1  problemType_2  \\\n",
       "184889     0.964225      -0.667735       0.451322       1.241278   \n",
       "184890    -1.419032      -0.667735       0.451322       1.241278   \n",
       "184891    -0.106654      -0.667735       0.451322       1.241278   \n",
       "184892    -1.168239      -0.667735       0.451322       1.241278   \n",
       "184893     1.239056       1.894327       1.007370      -0.444943   \n",
       "\n",
       "        assignmentId_0  assignmentId_1  assignmentId_2  assistmentId_0  \\\n",
       "184889        0.290601        0.774235        0.673495       -0.538666   \n",
       "184890        0.290601        0.774235        0.673495       -0.538666   \n",
       "184891        0.290601        0.774235        0.673495       -0.538666   \n",
       "184892        0.290601        0.774235        0.673495       -0.538666   \n",
       "184893        0.290601        0.774235        0.673495       -0.141623   \n",
       "\n",
       "        assistmentId_1  assistmentId_2  \n",
       "184889       -1.568210       -0.594635  \n",
       "184890       -1.568210       -0.594635  \n",
       "184891       -1.568210       -0.594635  \n",
       "184892       -1.568210       -0.594635  \n",
       "184893       -0.646897       -0.073348  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_train = open(DATA_DIR + \"student_train_logs.pickle\",\"rb\")\n",
    "train = pickle.load(pickle_train)\n",
    "\n",
    "train[9][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Here we define the parameters of the whole system, each parameter can be tweaked as needed:\n",
    "\n",
    "** System parameters**\n",
    "- **Validation_set_size** (int): The size of the validation set. Due to the poor amount of data that we are provided, the size of the validation set should be small.\n",
    "- **use_gpu** (bool): Use CUDA or not\n",
    "- **num_workers** (int): Maximum number of threads on the CPU.\n",
    "- **epochs** (int): Number of epochs\n",
    "\n",
    "** Model (RNN) parameters**\n",
    "- **dynamic_dim** (int): Number of dynamic features (that change at every action)\n",
    "- **fixed_dim** (int): Number of the static features (that are unchanged at every action)\n",
    "- **hidden_dim** (int): Number of features to be output by the Recurrent neural network \n",
    "- **n_layers** (int): Number of layers of the RNN\n",
    "- **bidirectional** (bool): To either use a bidirectional RNN or not\n",
    "- **dropout** (float in [0, 1]): Dropout of the RNN\n",
    "- **learning_rate** (float in [0, 1]): Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'validation_set_size': 30,\n",
    "    'dynamic_dim': train[9][0].shape[1],\n",
    "    'fixed_dim': train[9][1].shape[0],\n",
    "    'hidden_dim': 32,\n",
    "    'dropout': 0.1,\n",
    "    'n_layers': 3, \n",
    "    'bidirectional': True,\n",
    "    'use_gpu': False,\n",
    "    'learning_rate': 1e-3,\n",
    "    'epochs': 30,\n",
    "    'num_workers': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the validation set\n",
    "\n",
    "We create the validation set by randomly selecting `validation_set_size` students from the total training set and discarding those students from the actual training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = {k:v for k, v in random.sample(train.items(), parameters['validation_set_size'])}\n",
    "train_truncated = { k : train[k] for k in set(train) - set(validation) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Data Loader\n",
    "\n",
    "Now, we implement a data loader that will enable us to iterate through our data and transform our data into tensors to be used with pyTorch.\n",
    "\n",
    "With PyTorch, every DataLoader can be set a sampler that will define how the data is being sampled.\n",
    "Here we do not define any sampler but it could be a good idea to create a random weighted sampler in order to balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.idx = list(sequences.keys())\n",
    "        self.sequences = sequences\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10\n",
    "        #return len(self.sequences)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        student_id = self.idx[id]\n",
    "        \n",
    "        dynamic = self.sequences[student_id][0].as_matrix().astype(np.float32)\n",
    "        fixed = self.sequences[student_id][1].as_matrix().astype(np.float32)\n",
    "        target = np.asarray([self.sequences[student_id][2]]).astype(np.float32)\n",
    "\n",
    "        return student_id, dynamic, fixed, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_truncated)\n",
    "validation_dataset = DataSet(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN model\n",
    "\n",
    "Our RNN is composed of an LSTM or GRU that takes as data our sequence of actions per student. The LSTM outputs a number of hidden parameters on which we append our fixed features. We then fave a fully connected layer that takes as input our concatenated features and outputs a value. Finally, we use the sigmoid function to output a probability that the student will effectively do a career in STEM.\n",
    "\n",
    "Here are the functions explained:\n",
    "- **init**: Initializes the model by setting the parameters, creating a RNN layer and a Linear layer (fully connected).\n",
    "- **init_hidden**: Creates a zeroed initial hidden state.\n",
    "- **forward**: Actual RNN computation.\n",
    "- **step**: A step in the training process.\n",
    "- **evaluate_val**: Validation set results on the current model.\n",
    "- **fit**: Complete training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim,\n",
    "                 fixed_dim,\n",
    "                 n_layers,\n",
    "                 bi,\n",
    "                 use_gpu,\n",
    "                 dropout,\n",
    "                 output_dim=1,\n",
    "                 batch_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bi = bi\n",
    "        self.output_dim = output_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          dropout=dropout,\n",
    "                          bidirectional=bi)\n",
    "        if bi:\n",
    "            self.decoder = nn.Linear(hidden_dim*2 + fixed_dim, output_dim)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(hidden_dim + fixed_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.bi:\n",
    "            if self.use_gpu:\n",
    "                return Variable(torch.zeros(self.n_layers*2, self.batch_size, self.hidden_dim)).cuda()\n",
    "            else:\n",
    "                return Variable(torch.zeros(self.n_layers*2, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(self.n_layers, self.batch_size, self.hidden_dim)).cuda()\n",
    "        else:\n",
    "            return Variable(torch.zeros(self.n_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    \n",
    "    def forward(self, actions, fixed):\n",
    "        hidden_state = self.init_hidden()\n",
    "        out, _ = self.gru(actions, hidden_state)\n",
    "        out = self.decoder(torch.cat([out[-1, :, :], fixed], dim=1))                                                                                                   \n",
    "        out = out.view(self.batch_size, self.output_dim)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def step(self, dynamic, fixed, target):                                                                                                        \n",
    "        self.zero_grad()                                                                                                           \n",
    "        output = self.forward(dynamic, fixed)                                                                                                      \n",
    "        loss = self.criterion(output, target.float())                                                                      \n",
    "        loss.backward()                                                                                                                 \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.data[0], F.sigmoid(output)\n",
    "    \n",
    "    \n",
    "    def evaluate_val(self, dataset):\n",
    "        loader = DataLoader(dataset, self.batch_size, num_workers=parameters['num_workers'])\n",
    "        \n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        \n",
    "        self.eval()\n",
    "        print('before eval', self.training)\n",
    "        for i, (_, actions, fixed, target) in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "            y_true.append(target.float())\n",
    "            \n",
    "            actions = actions.permute(1, 0, 2)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                actions = Variable(actions).cuda()\n",
    "                fixed = Variable(fixed).cuda()\n",
    "            else:\n",
    "                actions = Variable(actions)\n",
    "                fixed = Variable(fixed)\n",
    "                \n",
    "            output = self.forward(actions, fixed)\n",
    "            output = F.sigmoid(output)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                y_preds.append(output.squeeze().cpu().data[0])\n",
    "            else:\n",
    "                y_preds.append(output.squeeze().data[0])\n",
    "        \n",
    "        return y_true, y_preds\n",
    "    \n",
    "    \n",
    "    def fit(self, train_dataset):\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adamax(self.parameters(), lr=parameters['learning_rate'])\n",
    "        \n",
    "        loader = DataLoader(train_dataset, batch_size=self.batch_size, num_workers=parameters['num_workers'], shuffle=True)\n",
    "        \n",
    "        e_losses = []\n",
    "        e_accs = []\n",
    "        e_aucs = []\n",
    "        e_mse = []\n",
    "\n",
    "        e_val_accs = []\n",
    "        e_val_aucs = []\n",
    "        e_val_mse = []\n",
    "        \n",
    "        e_bar = tqdm_notebook(range(parameters['epochs']))\n",
    "        for e in e_bar:\n",
    "            self.train()\n",
    "            e_loss = 0\n",
    "            preds = []\n",
    "            targets = []\n",
    "            val_preds = []\n",
    "            \n",
    "            for i, (_, seq, fixed, label) in enumerate(tqdm_notebook(loader, leave=False)):\n",
    "                seq = seq.permute(1,0,2)\n",
    "                \n",
    "                if self.use_gpu:\n",
    "                    seq_var = Variable(seq).cuda()\n",
    "                    fixed_var = Variable(fixed).cuda()\n",
    "                    label_var = Variable(label).cuda()\n",
    "                else:\n",
    "                    seq_var = Variable(seq)\n",
    "                    fixed_var = Variable(fixed)\n",
    "                    label_var =  Variable(label)\n",
    "                \n",
    "                loss, output = self.step(seq_var, fixed_var, label_var)\n",
    "                e_loss += loss\n",
    "                \n",
    "                preds.append(output.squeeze().cpu().data[0])\n",
    "                targets.append(label.float())\n",
    "            \n",
    "            preds = np.array(preds)\n",
    "            targets = np.array(targets)\n",
    "            auc = roc_auc_score(targets, preds)\n",
    "            mse = mean_squared_error(targets, preds)\n",
    "            \n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            acc = accuracy_score(preds, targets)\n",
    "            \n",
    "            e_losses.append(e_loss / (i+1))\n",
    "            e_accs.append(acc)\n",
    "            e_aucs.append(auc)\n",
    "            e_mse.append(mse)\n",
    "\n",
    "            # Validation set accuracy, AUC and RMSE\n",
    "            val_acc = None\n",
    "            val_auc = None\n",
    "            val_mse = None\n",
    "            if validation_dataset is not None:\n",
    "                val_targets, val_preds = self.evaluate_val(validation_dataset)\n",
    "                val_targets = np.array(val_targets)\n",
    "                val_preds = np.array(val_preds)\n",
    "                val_auc = roc_auc_score(val_targets, val_preds)\n",
    "                val_mse = mean_squared_error(val_targets, val_preds)\n",
    "\n",
    "                val_preds[val_preds >= 0.5] = 1\n",
    "                val_preds[val_preds < 0.5] = 0\n",
    "                val_acc = accuracy_score(val_preds, val_targets)\n",
    "\n",
    "                e_val_accs.append(val_acc)\n",
    "                e_val_aucs.append(val_auc)\n",
    "                e_val_mse.append(val_mse)\n",
    "            \n",
    "            e_bar.set_postfix(acc=acc,\n",
    "                              e_loss=e_losses[-1],\n",
    "                              auc=auc,\n",
    "                              mse=mse,\n",
    "                              val_acc=val_acc,\n",
    "                              val_auc=val_auc,\n",
    "                              val_mse=val_mse)\n",
    "      \n",
    "        return e_losses, e_accs, e_aucs, e_mse, e_val_accs, e_val_aucs, e_val_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train our RNN, we use our previously defined DataLoader and try to minimize error. The optimization function chosen is **Adamax** and the loss function is **Binary Cross-Entropy with Logits**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (gru): GRU(66, 32, num_layers=3, dropout=0.1, bidirectional=True)\n",
       "  (decoder): Linear(in_features=76, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(input_dim=parameters['dynamic_dim'],\n",
    "            hidden_dim=parameters['hidden_dim'],\n",
    "            fixed_dim=parameters['fixed_dim'],\n",
    "            n_layers=parameters['n_layers'],\n",
    "            bi=parameters['bidirectional'],\n",
    "            use_gpu=parameters['use_gpu'],\n",
    "            dropout=parameters['dropout'])\n",
    "\n",
    "if parameters['use_gpu']:\n",
    "    model.cuda()\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8273b674fe7843d797d8bf37d89856bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfded03917cc4e72a665632d15264676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before eval False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103ab2fa0fe9467280c640f48feca1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b584d2e77d8a45559e78e027a85a235a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before eval False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f2b75308684a7e84a6af9f711a4b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92444449d2e4da6b10721afd5895922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before eval False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f89dac883b424fa65fcfc4e9346afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36b5b2b1b894b17896e8a92642f3eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before eval False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333cc4244ef1494c850534fc7b355c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-124:\n",
      "Process Process-123:\n",
      "Process Process-122:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-121:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dario/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-cb0e65766589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_aucs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_val_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_val_aucs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_val_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-058b979eb43d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataset)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mval_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0mval_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-058b979eb43d>\u001b[0m in \u001b[0;36mevaluate_val\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mfixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-058b979eb43d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, actions, fixed)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mresetgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0minputgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mnewgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_n\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewgate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnewgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e_losses, e_accs, e_aucs, e_mse, e_val_accs, e_val_aucs, e_val_mse = model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing results in pickles\n",
    "\n",
    "The results are stored in a dictionary with the following entries:\n",
    "- **parameters**: A dictionary of parameters for the given result\n",
    "- **losses**: The losses over time\n",
    "- **accs**: Accuracies over time for the training set\n",
    "- **aucs**: ROC AUC over time for the training set\n",
    "- **mse**: Mean Squared Error over time for the trainings set\n",
    "- **val_accs**: Accuracies over time for the validation set\n",
    "- **val_aucs**: ROC AUC over time for the validation set\n",
    "- **val_mse**: Mean Squared Error over time for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'parameters': parameters,\n",
    "    'losses': e_losses,\n",
    "    'accs': e_accs,\n",
    "    'aucs': e_aucs,\n",
    "    'mse': e_mse,\n",
    "    'val_accs': e_val_accs,\n",
    "    'val_aucs': e_val_aucs,\n",
    "    'val_mse': e_val_mse\n",
    "}\n",
    "\n",
    "save_pickle(data_to_store, 'results_' + str(parameters['hidden_dim']) + '_' + str(parameters['n_layers']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
